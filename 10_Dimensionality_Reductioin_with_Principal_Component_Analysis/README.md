# 10. Dimensionality Reduction with Principal Component Analysis

## 10.1 Problem Setting


## 10.2 Maximum Variance Perspective

### 10.2.1 Direction with Maximal Variance

### 10.2.2 M-dimensional Subspace with Maximal Variance

## 10.3 Projection Perspective

### 10.3.1 Setting and Objective

### 10.3.2 Finding Optimal Coordinates

### 10.3.3 Finding the Basis of the Principal Subspace


## 10.4 Eigenvector Computation and Low-Rank Approximations

### 10.4.1 PCA Using Low-Rank Matrix Approximations

### 10.4.2 Practical Aspects

## 10.5 PCA in High Dimensions

## 10.6 Key Steps of PCA in Practice

## 10.7 Latent Variable Perspective

### 10.7.1 Generative Process and Probabilistic Model

### 10.7.2 Likelihood and Joint Distribution

### 10.7.3 Posterior Distribution
